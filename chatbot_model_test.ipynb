{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot_model_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg8FWJRiLOy11XJETket1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fkrhtmq123/Tensorflow/blob/master/chatbot_model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0a4E11fm4y5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e35f4413-db40-49ed-90d6-cebf849e0d41"
      },
      "source": [
        "# 구글 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEEwxzEJmxlh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필요 패키지 임포트\n",
        "import codecs\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import random, sys\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Activation, Dropout, Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.models import load_model\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DdRFM07nD_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61f3d9cd-5c02-4a8b-fc55-188c2ebd750c"
      },
      "source": [
        "# 모델 로드\n",
        "model = load_model('/content/drive/My Drive/Tensorflow_works/model/chatbot.model')\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f998a86cd30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1jb7AUmnLvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 파일 로드 함수정의\n",
        "def load_data(file):\n",
        "  result = []\n",
        "\n",
        "  with open(file, 'r', encoding='utf-8') as f:\n",
        "    lines = f.read().splitlines()\n",
        "\n",
        "    for line in lines:\n",
        "      data = line.split(',')\n",
        "      data = data[0] + ' ' + data[1] + '\\n'\n",
        "      result.append(data)\n",
        "\n",
        "  result = result[1:] # header정보 제외\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urtsGlkbnQos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 로드\n",
        "chat_dataset = load_data('/content/drive/My Drive/Tensorflow_works/data/ChatbotData.csv')\n",
        "text = ' '.join(chat_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfkCYP3_ndXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문자 토큰화\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "voca_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9tb5ThVfnjG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장 생성 함수정의\n",
        "def sentence_generate(model, question):\n",
        "  init_word = question\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(3):\n",
        "\n",
        "    encoded = tokenizer.texts_to_sequences([question])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=20, padding='pre')\n",
        "\n",
        "    result = model.predict_classes(encoded, verbose=0)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    question = question + ' ' + word\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI61ypjQgzfL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d905b919-2986-417f-ae5e-a9144189458e"
      },
      "source": [
        "sentence_generate(model, \"안녕\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 99) for input Tensor(\"embedding_input_3:0\", shape=(None, 99), dtype=float32), but it was called on an input with incompatible shape (None, 20).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' 안녕하세요 거의안나 꼭'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}